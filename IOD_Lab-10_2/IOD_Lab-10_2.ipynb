{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHTopEExiUBi"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxpWSUtUiUBl"
   },
   "source": [
    "# Lab 10.2 - Deployment via Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HflomFnQiUBn"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WwXJxFEiUBp"
   },
   "source": [
    "**Note**: This notebook should work on your local machine.\n",
    "\n",
    "The purpose of this lab is to take you through the process of deploying a machine learning web app on a publicly hosted platform (streamlit.io and optionally render.com). A trained model will be created using the Scikit-learn pipeline (combining loading, preprocessing and training steps), then separate files of Python code and text will need to be completed to make deployment possible. Firstly the app will be deployed to your local machine (so that you can view it in your browser). Once that it is successful, the files will be uploaded to a new repository you create in GitHub and then Streamlit or Render will read from this to host the application via a publicly accessible URL.\n",
    "\n",
    "The app will take in a text string from a user and output a prediction of whether that string is expressing positive or negative sentiment. The model is created using methods from Module 8 (Natural Language Processing). Since the training data used to create the model is small (300 records), the prediction may only be accurate around 70% of the time. In future you may wish to improve this app's performance or develop your own app in a similar manner.\n",
    "\n",
    "The following files are needed to create the app (they should be in the same folder as this notebook):\n",
    "\n",
    "- requirements.txt\n",
    "- app.py\n",
    "- model.joblib\n",
    "- utils.py\n",
    "- .streamlit/ (folder containing config.toml)\n",
    "\n",
    "\n",
    "Firstly we will see how a predictive model can be created as a pipe which combines the preprocessing, feature engineering and model training steps. This model is then saved as a joblib pickle file which can be reloaded at any time to avoid retraining.\n",
    "\n",
    "This trained model can be loaded within your production environment along with required packages and real-time predictions can be made by calling its predict() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERrfJI4liUBr"
   },
   "source": [
    "Streamlit enables apps to be deployed rapidly with minimal knowledge of HTML or CSS. Some of the key concepts are described at https://docs.streamlit.io/get-started/fundamentals/main-concepts. Sample apps can be seen at https://streamlit.io/gallery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN2_pQpQiUBs"
   },
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/61.0 kB 281.8 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.0 kB 327.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 271.7 kB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.2/15.8 MB 3.4 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.4/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.6/15.8 MB 3.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.4/15.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 6.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.2/15.8 MB 6.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.5/15.8 MB 6.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/15.8 MB 7.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.3/15.8 MB 8.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.8/15.8 MB 8.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.2/15.8 MB 8.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.1/15.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.7/15.8 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.1/15.8 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.7/15.8 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.1/15.8 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.6/15.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.4/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.0/15.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.0/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.4/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 8.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\willv\\AppData\\Local\\Temp\\pip-uninstall-ox8j6vu5'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\willv\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 165.2 kB/s eta 0:01:18\n",
      "     --------------------------------------- 0.1/12.8 MB 409.6 kB/s eta 0:00:32\n",
      "      --------------------------------------- 0.2/12.8 MB 1.3 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.6/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/12.8 MB 3.8 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 5.3 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.2/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.8/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.0/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 7.5 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.3/12.8 MB 7.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.7/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.2/12.8 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.5/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 6.9/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.4/12.8 MB 8.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.8 MB 8.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.4/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.8/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 11.3/12.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.8/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 12.4/12.8 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.7/12.8 MB 10.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 9.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v_6bsZ17iUBt"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import spacy\n",
    "import streamlit as st\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHfolmVhiUBv"
   },
   "source": [
    "The training data set is `sentiments.csv`, a dataset used in the NLP module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gbKJ-_fBiUBw"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "igLwTWDWiUBx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "br8BRKxNiUBy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment source\n",
       "0                           Wow... Loved this place.          1   yelp\n",
       "1                                 Crust is not good.          0   yelp\n",
       "2          Not tasty and the texture was just nasty.          0   yelp\n",
       "3  Stopped by during the late May bank holiday of...          1   yelp\n",
       "4  The selection on the menu was great and so wer...          1   yelp"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6NLlNXUiUB0"
   },
   "source": [
    "Next we define a function to do some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sNQ24V0yiUB0"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5vYhCV2IiUB1"
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f84DgJ0aiUB1"
   },
   "source": [
    "The following NLP model is used for further preprocessing. The following steps are the same as used in Module 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "enm2PjpaiUB2"
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PMzvs-BZiUB3"
   },
   "outputs": [],
   "source": [
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_3By-j1iiUB3"
   },
   "outputs": [],
   "source": [
    "df['short'] = df['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vEIdN7EGiUB3"
   },
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = df['short']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aXyfC5FCiUB5"
   },
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BYZdTo-5iUB5"
   },
   "outputs": [],
   "source": [
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7LlE0m1viUB5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7767\n"
     ]
    }
   ],
   "source": [
    "# create a matrix of word counts from the text\n",
    "# use TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "# do the actual counting\n",
    "A = tfidf.fit_transform(X_train, y_train)\n",
    "\n",
    "# train the classifier with the training data\n",
    "classifier.fit(A.toarray(), y_train)\n",
    "\n",
    "# do the transformation for the test data\n",
    "# NOTE: use `transform()` instead of `fit_transform()`\n",
    "B = tfidf.transform(X_test)\n",
    "\n",
    "# make predictions based on the test data\n",
    "predictions = classifier.predict(B)\n",
    "\n",
    "# check the accuracy\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRWXDzW4iUB6"
   },
   "source": [
    "We will not attempt to improve on the performance in this lab as we are more interested in how to deploy the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRqj30DAiUB6"
   },
   "source": [
    "Next we create a pipeline to simplify the process of model creation. We first define a preprocessor class which applies the `clean_text` and `convert_text` functions defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zis7wgBviUB6"
   },
   "outputs": [],
   "source": [
    "class preprocessor(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "         return X.apply(clean_text).apply(convert_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgRreTmIiUB9"
   },
   "source": [
    "Next we combine the preprocessing, feature engineering and modelling steps into a single pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zDWM04TCiUB9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;, preprocessor()),\n",
       "                (&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;, preprocessor()),\n",
       "                (&#x27;tfidfvectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor</label><div class=\"sk-toggleable__content\"><pre>preprocessor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor', preprocessor()),\n",
       "                ('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('linearsvc', LinearSVC())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(preprocessor(), tfidf, classifier)\n",
    "pipe.fit(df['text'],df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf4sc-UdiUB-"
   },
   "source": [
    "**Exercise**: test the resulting model on phrases of positive and negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_6QcSN15iUB-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series('bad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aYX5-nrwiUB-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series('good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series('goblin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCdggHDOiUB-"
   },
   "source": [
    "Once satisfied that we have a model ready for deployment, we can write a self-contained script that creates the model and saves it as a joblib file. By doing so from a script rather than the notebook we simplify the process when deploying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDMytUE1iUB-"
   },
   "source": [
    "**Exercise**:\n",
    "1. Review the code in model.py.\n",
    "2. Open an Anaconda prompt (Windows) or Terminal window (Mac).\n",
    "3. Navigate to the folder where model.py is located using the command `cd \"<path to your folder>\"`.\n",
    "4. At the prompt enter `python model.py`. After a few moments this creates a file `model.joblib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIv9i9vNiUB_"
   },
   "source": [
    "Let us load this model and verify that it alone can be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ia8JvW8NiUCA"
   },
   "outputs": [],
   "source": [
    "newpipe = joblib.load(open('model.joblib','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CMwc4oNTiUCA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newpipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfDAsTeniUCA"
   },
   "source": [
    "Testing this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8N95G-HAiUCB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(newpipe.predict(pd.Series('awesome place'))[0])\n",
    "print(newpipe.predict(pd.Series('terrible!'))[0])\n",
    "print(newpipe.predict(pd.Series('very interesting'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6tLRTVpiUCC"
   },
   "source": [
    "We can then write a self-contained script that loads the model and can make predictions on the fly. This is partially done for you in the file \"app.py\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEYFUMNbiUCC"
   },
   "source": [
    "**Exercise**: Refer to app.py and fill in the missing code based on the code above using a text editor such as Spyder or even Jupyter. Observe how it links to utils.py which contains the preprocessing functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kwvz-TZNiUCC"
   },
   "source": [
    "### Local hosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ei78oDriiUCD"
   },
   "source": [
    "Using Anaconda prompt (Windows) or a Terminal window (Mac) run \"streamlit run app.py\". This deploys the app locally on http://localhost:8501/ (or similar) which you can then view on the browser. The file app.py may require debugging before it runs successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQKAa2GJiUCE"
   },
   "source": [
    "**Bonus Exercise**: Redesign the webpage by adding other components. You can use the cheat sheet at https://docs.streamlit.io/library/cheatsheet as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMaxdLgUiUCE"
   },
   "source": [
    "### Deployment via streamlit.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8d2Q7M6iUCF"
   },
   "source": [
    "So far you have deployed your model on your local machine. Now we seek to deploy it publicly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw46UOOtopJn"
   },
   "source": [
    "streamlit.io is intended to deploy Streamlit apps seamlessly without worrying about infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZ_WOZKHiUCF"
   },
   "source": [
    "There is one additional file needed for external deployment of your model:\n",
    "- requirements.txt includes the versions of packages that are to be used with the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTYxx7-giUCG"
   },
   "source": [
    "To update the `requirements.txt` file use the `__version__` attribute to see the version of packages being used. This ensures that your model is reproducible on other computing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6-bAwKxQiUCG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lG0YXqz8opJn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.30.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA00bwvjiUCH"
   },
   "source": [
    "Log into your GitHub account (create one if you have not already done so) and create a new repository containing the following files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neQNxDdhiUCH"
   },
   "source": [
    "- requirements.txt\n",
    "- app.py\n",
    "- model.joblib\n",
    "- utils.py\n",
    "- .streamlit/ (folder containing config.toml)\n",
    "\n",
    "This config.toml allows one to set themes such as the type of background to display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b4GekP1opJn"
   },
   "source": [
    "Next sign up for a free account at https://streamlit.io/ and once signed in, go to https://share.streamlit.io/ and click the blue \"New app\" button. Under \"Repository\" specify the GitHub repository where your app is located (in the form username/reponame). The default URL is based on the app's location in GitHub, but that may be changed. Under \"main file path\" enter `app.py` replacing `streamlit-app.py`. Finally click the \"Deploy!\" button. If successful the app will deployed to the specified url (it may take several minutes). An example can be seen at https://iod-sentiment-app.streamlit.app/.\n",
    "\n",
    "If there are issues, click on the \"Manage app\" button at the bottom right to view the app's logs. Files such as requirements.txt can be edited directly within GitHub.\n",
    "\n",
    "Further details are at https://docs.streamlit.io/streamlit-community-cloud/manage-your-app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owpp41S-iUCK"
   },
   "source": [
    "If you managed to see your app successfully, congratulations! You now know how to deploy an app on the cloud. To make it visible to others, go to your app's settings and under \"Sharing\" -> \"Who can view this app\" select \"This app is public and searchable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjA-LCp-opJn"
   },
   "source": [
    "### Deployment via render.com (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM1hfRxhopJn"
   },
   "source": [
    "Render is a general-purpose cloud platform that goes beyond deploying streamlit apps. It can host a broader range of web applications, APIs, databases and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d5oY4LSiUCI"
   },
   "source": [
    "Sign up for a free account at https://dashboard.render.com/register (a Platform As A Service) by connecting via your GitHub account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k88ygpMIiUCI"
   },
   "source": [
    "Once signed into dashboard.render.com click \"New Web Service\" under Web Services.\n",
    "\n",
    "From \"connect GitHub account\", select the repository containing the above files.\n",
    "\n",
    "Choose a unique name for the web service and leave the root directory blank. Under \"start command\" enter `streamlit run app.py`.\n",
    "\n",
    "Finally click \"Create Web Service\". It may take a few minutes to work but\n",
    "upon seeing \"Booting worker with pid:\" go to the url specified. An example can be seen at https://streamlit-sentiment.onrender.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_icdjyIiUCK"
   },
   "source": [
    "Note that if working in part of a larger software system it is good practice to have versioning of code (e.g. with GitHub) and also make use of CI/CD software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJNvVjNOiUCK"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcQqPISLiUCL"
   },
   "source": [
    "More information on pipelines:\n",
    "- https://gist.github.com/amberjrivera/8c5c145516f5a2e894681e16a8095b5c\n",
    "- https://scikit-learn.org/stable/modules/compose.html#pipeline\n",
    "\n",
    "Deploying Streamlit apps on Render and Streamlit Cloud:\n",
    "- https://www.youtube.com/watch?v=bXRVgg2iWyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhwYvgd2iUCL"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2024 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
